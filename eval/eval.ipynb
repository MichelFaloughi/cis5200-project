{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2750255c",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Evaluate all wind speed prediction models using the evaluation framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e44a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from eval_helpers import evaluate, plot_predictions, compare\n",
    "from data.data_helpers import get_dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d5943",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f851f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'cds.climate.copernicus.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2018_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2018_H2.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2019_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2019_H2.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2020_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2020_H2.nc\n",
      "Training set: 17,520 samples\n",
      "Test set: 8,783 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = get_dataframe()\n",
    "df = df.dropna(subset=[\"target_next_hour\"])\n",
    "\n",
    "# Temporal split: 2018-2019 for training, 2020 for testing\n",
    "train_df = df[df[\"datetime\"] < \"2020-01-01\"].copy()\n",
    "test_df = df[df[\"datetime\"] >= \"2020-01-01\"].copy()\n",
    "\n",
    "print(f\"Training set: {len(train_df):,} samples\")\n",
    "print(f\"Test set: {len(test_df):,} samples\")\n",
    "\n",
    "# Store datetime for plotting\n",
    "test_datetime = test_df[\"datetime\"].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fbb86",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "\n",
    "Evaluate each model and collect results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results from all models\n",
    "results = []\n",
    "\n",
    "# TODO: Add your models here\n",
    "# Example:\n",
    "# from models.model0 import PersistenceModel\n",
    "# model0 = PersistenceModel()\n",
    "# result0 = evaluate(model0, X_train_m0, y_train_m0, X_test_m0, y_test_m0, model_name=\"PersistenceBaseline\")\n",
    "# results.append(result0)\n",
    "# plot_predictions(y_test_m0, result0['predictions'], model_name=\"PersistenceBaseline\", datetime_index=test_datetime)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Questions:\n",
    "# how to add a model ? What properties should it have ? like a .predict() method ? or a .fit() method ? or something else ?\n",
    "# how to keep track of the loss function ? etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e3971",
   "metadata": {},
   "source": [
    "## Compare All Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5d384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models evaluated yet. Add your models in the section above.\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "if len(results) > 0:\n",
    "    scorecard = compare(results, plot=True)\n",
    "else:\n",
    "    print(\"No models evaluated yet. Add models in the section above.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
