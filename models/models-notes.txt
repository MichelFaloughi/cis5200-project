model 0 — PersistenceBaseline
- Predicts $y_t$ = last observed wind_speed ($y_{t-1}$).
- Zero training cost; sanity check that every other model adds value.

model 1 — LinearRegressionModel
- Scikit-learn LinearRegression optionally preceded by StandardScaler.
- Uses all engineered tabular features (cyclical time encodings + physical measurements, excluding `datetime`/`target_next_hour`).
- Provides interpretable coefficients for narrative about linear structure.

model 2 — RandomForestModel
- Classic bagged decision-tree ensemble (`RandomForestRegressor`).
- Same feature view as model 1; automatically captures nonlinear interactions and variable importance without heavy tuning.

model 3 — XGBoostModel
- Gradient boosting over lagged versions of key meteorological variables (`u10`, `v10`, `t2m`, `sp`, `wind_speed`) plus cyclic time features.
- Internally builds lag windows (default 24 h) and masks initial NaNs; strongest tree-based baseline.

model 4 — MLPModel
- Feed-forward network wrapped in a `StandardScaler → MLPRegressor` pipeline (default hidden sizes 200×100, ReLU, Adam).
- Operates on the same flattened engineered features as models 1/2; good point of comparison vs ensembles.

model 5 — TransformerModel
- PyTorch encoder-only transformer with positional encoding over feature dimension, trained on standardized tabular features.
- Includes checkpointing/early stopping; loads from `models/artifacts/model5/transformer_model.pt` for reuse.


Why this is good/what we should strive for
Covers classical → ML → ensemble → DL in a clean progression
Gives faculty exactly what they want: comparative study, clear baselines, method variety



---
Loss functions: currently standard regression losses via scikit-learn/PyTorch (MAE/RMSE), but consider:
- Wind-aware penalties (e.g., upweight strong-wind errors, asymmetric loss).
- Hybrid objectives (MSE + MAE or smoothness regularizers) for the neural models.

---
All production models now expose consistent `fit()` / `predict()` APIs, enabling unified evaluation in `eval/eval.ipynb` and via `models.registry.get_model(...)`.

