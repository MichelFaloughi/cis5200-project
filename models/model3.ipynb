{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 5200 – XGBoost Wind Speed Forecasting\n",
    "\n",
    "This notebook trains an **XGBoost regression model** to forecast **1-hour-ahead wind speed** at the Tehachapi wind farm using ERA5 reanalysis data.\n",
    "\n",
    "We assume your DataFrame already contains:\n",
    "- `datetime`\n",
    "- ERA5 physical vars: `u10`, `v10`, `t2m`, `sp`\n",
    "- time encodings: `hour_sin`, `hour_cos`, `month_sin`, `month_cos`, `doy_sin`, `doy_cos`\n",
    "- `wind_speed`\n",
    "- `target_next_hour`\n",
    "\n",
    "The goal is to build 24-hour lagged features, train XGBoost, and evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and imports\n",
    "Install dependencies if needed and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If xgboost is not installed, uncomment the next line:\n",
    "# !pip install xgboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load your preprocessed dataset\n",
    "Set the correct path to your processed CSV file.\n",
    "\n",
    "If you already have `df` in memory, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2018_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2018_H2.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2019_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2019_H2.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2020_H1.nc\n",
      "Skipping existing file /Users/aboulmich/Projects/cis5200-project/data/era5_tehachapi_2020_H2.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'cds.climate.copernicus.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>t2m</th>\n",
       "      <th>sp</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>target_next_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>-0.808231</td>\n",
       "      <td>-0.069685</td>\n",
       "      <td>291.890625</td>\n",
       "      <td>89925.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.811229</td>\n",
       "      <td>1.524293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>-1.340298</td>\n",
       "      <td>-0.725997</td>\n",
       "      <td>290.692627</td>\n",
       "      <td>89972.2500</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.524293</td>\n",
       "      <td>1.245654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>-0.462882</td>\n",
       "      <td>-1.156458</td>\n",
       "      <td>288.544922</td>\n",
       "      <td>90036.1875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.245654</td>\n",
       "      <td>1.053555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>0.300817</td>\n",
       "      <td>-1.009697</td>\n",
       "      <td>285.121826</td>\n",
       "      <td>90091.3125</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.053555</td>\n",
       "      <td>1.122294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>0.736362</td>\n",
       "      <td>-0.846944</td>\n",
       "      <td>283.715820</td>\n",
       "      <td>90125.1250</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.363163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime       u10       v10         t2m          sp  hour_sin  \\\n",
       "0 2018-01-01 00:00:00 -0.808231 -0.069685  291.890625  89925.2500  0.000000   \n",
       "1 2018-01-01 01:00:00 -1.340298 -0.725997  290.692627  89972.2500  0.258819   \n",
       "2 2018-01-01 02:00:00 -0.462882 -1.156458  288.544922  90036.1875  0.500000   \n",
       "3 2018-01-01 03:00:00  0.300817 -1.009697  285.121826  90091.3125  0.707107   \n",
       "4 2018-01-01 04:00:00  0.736362 -0.846944  283.715820  90125.1250  0.866025   \n",
       "\n",
       "   hour_cos  month_sin  month_cos   doy_sin   doy_cos  wind_speed  \\\n",
       "0  1.000000        0.5   0.866025  0.017213  0.999852    0.811229   \n",
       "1  0.965926        0.5   0.866025  0.017213  0.999852    1.524293   \n",
       "2  0.866025        0.5   0.866025  0.017213  0.999852    1.245654   \n",
       "3  0.707107        0.5   0.866025  0.017213  0.999852    1.053555   \n",
       "4  0.500000        0.5   0.866025  0.017213  0.999852    1.122294   \n",
       "\n",
       "   target_next_hour  \n",
       "0          1.524293  \n",
       "1          1.245654  \n",
       "2          1.053555  \n",
       "3          1.122294  \n",
       "4          1.363163  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from data.data_helpers import get_dataframe\n",
    "\n",
    "df = get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort by time and create lagged features\n",
    "\n",
    "We model 1-hour-ahead wind speed using **the last 24 hours of history** for each variable:\n",
    "- u10, v10\n",
    "- t2m\n",
    "- surface pressure (sp)\n",
    "- wind_speed\n",
    "\n",
    "Lag features: `var_lag0`, `var_lag1`, ..., `var_lag23`.\n",
    "\n",
    "We also keep cycle features: hour/month/day-of-year sin/cos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after lagging: (26280, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
      "/var/folders/hv/j0lkhp0s4fq2j90h3ylspdpm0000gn/T/ipykernel_91185/2022331926.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>t2m</th>\n",
       "      <th>sp</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_lag14</th>\n",
       "      <th>wind_speed_lag15</th>\n",
       "      <th>wind_speed_lag16</th>\n",
       "      <th>wind_speed_lag17</th>\n",
       "      <th>wind_speed_lag18</th>\n",
       "      <th>wind_speed_lag19</th>\n",
       "      <th>wind_speed_lag20</th>\n",
       "      <th>wind_speed_lag21</th>\n",
       "      <th>wind_speed_lag22</th>\n",
       "      <th>wind_speed_lag23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>-2.007515</td>\n",
       "      <td>-0.398896</td>\n",
       "      <td>288.983398</td>\n",
       "      <td>90245.1875</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>...</td>\n",
       "      <td>1.689377</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>1.577095</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.363163</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.053555</td>\n",
       "      <td>1.245654</td>\n",
       "      <td>1.524293</td>\n",
       "      <td>0.811229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>-1.891289</td>\n",
       "      <td>-0.214457</td>\n",
       "      <td>288.743408</td>\n",
       "      <td>90263.5625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.442469</td>\n",
       "      <td>1.689377</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>1.577095</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.363163</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.053555</td>\n",
       "      <td>1.245654</td>\n",
       "      <td>1.524293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-02 01:00:00</td>\n",
       "      <td>-1.858377</td>\n",
       "      <td>-0.074957</td>\n",
       "      <td>287.475342</td>\n",
       "      <td>90278.1875</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.411922</td>\n",
       "      <td>1.442469</td>\n",
       "      <td>1.689377</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>1.577095</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.363163</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.053555</td>\n",
       "      <td>1.245654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-02 02:00:00</td>\n",
       "      <td>-1.165116</td>\n",
       "      <td>-0.878426</td>\n",
       "      <td>287.569824</td>\n",
       "      <td>90315.6250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461147</td>\n",
       "      <td>1.411922</td>\n",
       "      <td>1.442469</td>\n",
       "      <td>1.689377</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>1.577095</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.363163</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.053555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-02 03:00:00</td>\n",
       "      <td>-0.596005</td>\n",
       "      <td>-1.192101</td>\n",
       "      <td>284.457031</td>\n",
       "      <td>90319.4375</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460693</td>\n",
       "      <td>1.461147</td>\n",
       "      <td>1.411922</td>\n",
       "      <td>1.442469</td>\n",
       "      <td>1.689377</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>1.577095</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>1.363163</td>\n",
       "      <td>1.122294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime       u10       v10         t2m          sp  hour_sin  \\\n",
       "23 2018-01-01 23:00:00 -2.007515 -0.398896  288.983398  90245.1875 -0.258819   \n",
       "24 2018-01-02 00:00:00 -1.891289 -0.214457  288.743408  90263.5625  0.000000   \n",
       "25 2018-01-02 01:00:00 -1.858377 -0.074957  287.475342  90278.1875  0.258819   \n",
       "26 2018-01-02 02:00:00 -1.165116 -0.878426  287.569824  90315.6250  0.500000   \n",
       "27 2018-01-02 03:00:00 -0.596005 -1.192101  284.457031  90319.4375  0.707107   \n",
       "\n",
       "    hour_cos  month_sin  month_cos   doy_sin  ...  wind_speed_lag14  \\\n",
       "23  0.965926        0.5   0.866025  0.017213  ...          1.689377   \n",
       "24  1.000000        0.5   0.866025  0.034422  ...          1.442469   \n",
       "25  0.965926        0.5   0.866025  0.034422  ...          1.411922   \n",
       "26  0.866025        0.5   0.866025  0.034422  ...          1.461147   \n",
       "27  0.707107        0.5   0.866025  0.034422  ...          1.460693   \n",
       "\n",
       "    wind_speed_lag15  wind_speed_lag16  wind_speed_lag17  wind_speed_lag18  \\\n",
       "23          1.627172          1.577095          1.499427          1.363163   \n",
       "24          1.689377          1.627172          1.577095          1.499427   \n",
       "25          1.442469          1.689377          1.627172          1.577095   \n",
       "26          1.411922          1.442469          1.689377          1.627172   \n",
       "27          1.461147          1.411922          1.442469          1.689377   \n",
       "\n",
       "    wind_speed_lag19  wind_speed_lag20  wind_speed_lag21  wind_speed_lag22  \\\n",
       "23          1.122294          1.053555          1.245654          1.524293   \n",
       "24          1.363163          1.122294          1.053555          1.245654   \n",
       "25          1.499427          1.363163          1.122294          1.053555   \n",
       "26          1.577095          1.499427          1.363163          1.122294   \n",
       "27          1.627172          1.577095          1.499427          1.363163   \n",
       "\n",
       "    wind_speed_lag23  \n",
       "23          0.811229  \n",
       "24          1.524293  \n",
       "25          1.245654  \n",
       "26          1.053555  \n",
       "27          1.122294  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure sorted by datetime\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "LAG_HOURS = 24\n",
    "\n",
    "lag_vars = [\"u10\", \"v10\", \"t2m\", \"sp\", \"wind_speed\"]\n",
    "time_features = [\"hour_sin\", \"hour_cos\", \"month_sin\", \"month_cos\", \"doy_sin\", \"doy_cos\"]\n",
    "\n",
    "# Construct lagged features\n",
    "for var in lag_vars:\n",
    "    for lag in range(LAG_HOURS):\n",
    "        df[f\"{var}_lag{lag}\"] = df[var].shift(lag)\n",
    "\n",
    "# Drop rows with NA due to shifting\n",
    "df_ml = df.dropna(subset=[\"target_next_hour\"] + [f\"{v}_lag{LAG_HOURS-1}\" for v in lag_vars]).copy()\n",
    "\n",
    "print(\"Dataset after lagging:\", df_ml.shape)\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build train/val/test splits (chronological)\n",
    "\n",
    "We use 70% for training, 15% validation, 15% testing.\n",
    "\n",
    "Time-series splitting **does NOT shuffle**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18396, 126)\n",
      "Val:   (3942, 126)\n",
      "Test:  (3942, 126)\n"
     ]
    }
   ],
   "source": [
    "lag_feature_cols = [c for c in df_ml.columns if any(c.startswith(v + \"_lag\") for v in lag_vars)]\n",
    "feature_cols = lag_feature_cols + time_features\n",
    "\n",
    "X = df_ml[feature_cols].to_numpy()\n",
    "y = df_ml[\"target_next_hour\"].to_numpy()\n",
    "\n",
    "N = len(df_ml)\n",
    "train_end = int(0.7 * N)\n",
    "val_end = int(0.85 * N)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:  \", X_val.shape)\n",
    "print(\"Test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost model\n",
    "\n",
    "This configuration is lightweight but performant. Increase trees/depth later if you want more power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "XGBModel.fit() got an unexpected keyword argument 'eval_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBRegressor(\n\u001b[1;32m      2\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: XGBModel.fit() got an unexpected keyword argument 'eval_metric'"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_metric=\"rmse\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate model\n",
    "Compute MAE, RMSE, and R² on the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MAE:  {mae:.4f}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature importance\n",
    "Visualize the top 20 most important lag features used by XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "top_k = 20\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh([feature_cols[i] for i in indices[:top_k]][::-1],\n",
    "         importances[indices[:top_k]][::-1])\n",
    "plt.title(\"XGBoost Feature Importance – Top 20\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
