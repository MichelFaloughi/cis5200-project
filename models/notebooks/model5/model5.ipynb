{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77568563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from data.data_helpers import get_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9939d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\Language\\Python\\VirtualEnvs\\cis5200\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'cds.climate.copernicus.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2018_H1.nc\n",
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2018_H2.nc\n",
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2019_H1.nc\n",
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2019_H2.nc\n",
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2020_H1.nc\n",
      "Skipping existing file C:\\Coding\\Github-Repo\\CIS-5200-Project\\data\\era5_tehachapi_2020_H2.nc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>t2m</th>\n",
       "      <th>sp</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>target_next_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>-0.808231</td>\n",
       "      <td>-0.069685</td>\n",
       "      <td>291.890625</td>\n",
       "      <td>89925.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.811229</td>\n",
       "      <td>1.524293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>-1.340298</td>\n",
       "      <td>-0.725997</td>\n",
       "      <td>290.692627</td>\n",
       "      <td>89972.2500</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.524293</td>\n",
       "      <td>1.245654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>-0.462882</td>\n",
       "      <td>-1.156458</td>\n",
       "      <td>288.544922</td>\n",
       "      <td>90036.1875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.245654</td>\n",
       "      <td>1.053555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>0.300817</td>\n",
       "      <td>-1.009697</td>\n",
       "      <td>285.121826</td>\n",
       "      <td>90091.3125</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.053555</td>\n",
       "      <td>1.122294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>0.736362</td>\n",
       "      <td>-0.846944</td>\n",
       "      <td>283.715820</td>\n",
       "      <td>90125.1250</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.122294</td>\n",
       "      <td>1.363163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime       u10       v10         t2m          sp  hour_sin  \\\n",
       "0 2018-01-01 00:00:00 -0.808231 -0.069685  291.890625  89925.2500  0.000000   \n",
       "1 2018-01-01 01:00:00 -1.340298 -0.725997  290.692627  89972.2500  0.258819   \n",
       "2 2018-01-01 02:00:00 -0.462882 -1.156458  288.544922  90036.1875  0.500000   \n",
       "3 2018-01-01 03:00:00  0.300817 -1.009697  285.121826  90091.3125  0.707107   \n",
       "4 2018-01-01 04:00:00  0.736362 -0.846944  283.715820  90125.1250  0.866025   \n",
       "\n",
       "   hour_cos  month_sin  month_cos   doy_sin   doy_cos  wind_speed  \\\n",
       "0  1.000000        0.5   0.866025  0.017213  0.999852    0.811229   \n",
       "1  0.965926        0.5   0.866025  0.017213  0.999852    1.524293   \n",
       "2  0.866025        0.5   0.866025  0.017213  0.999852    1.245654   \n",
       "3  0.707107        0.5   0.866025  0.017213  0.999852    1.053555   \n",
       "4  0.500000        0.5   0.866025  0.017213  0.999852    1.122294   \n",
       "\n",
       "   target_next_hour  \n",
       "0          1.524293  \n",
       "1          1.245654  \n",
       "2          1.053555  \n",
       "3          1.122294  \n",
       "4          1.363163  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fc6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['datetime', 'target_next_hour']).copy()\n",
    "y = df['target_next_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939ae83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10615136476061003\n",
      "R²: 0.9400115895471047\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split data (keep time order)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Pipeline: scaler + MLP\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPRegressor(\n",
    "        hidden_layer_sizes=(200, 100),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        early_stopping=False,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=10,\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6a78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.934030 | Val Loss: 0.233371 | Wait: 0/8\n",
      "Epoch 002 | Train Loss: 0.227914 | Val Loss: 0.168632 | Wait: 0/8\n",
      "Epoch 002 | Train Loss: 0.227914 | Val Loss: 0.168632 | Wait: 0/8\n",
      "Epoch 003 | Train Loss: 0.205514 | Val Loss: 0.166541 | Wait: 0/8\n",
      "Epoch 003 | Train Loss: 0.205514 | Val Loss: 0.166541 | Wait: 0/8\n",
      "Epoch 004 | Train Loss: 0.205116 | Val Loss: 0.156338 | Wait: 0/8\n",
      "Epoch 004 | Train Loss: 0.205116 | Val Loss: 0.156338 | Wait: 0/8\n",
      "Epoch 005 | Train Loss: 0.202219 | Val Loss: 0.180506 | Wait: 1/8\n",
      "Epoch 005 | Train Loss: 0.202219 | Val Loss: 0.180506 | Wait: 1/8\n",
      "Epoch 006 | Train Loss: 0.198540 | Val Loss: 0.168357 | Wait: 2/8\n",
      "Epoch 006 | Train Loss: 0.198540 | Val Loss: 0.168357 | Wait: 2/8\n",
      "Epoch 007 | Train Loss: 0.195995 | Val Loss: 0.161549 | Wait: 3/8\n",
      "Epoch 007 | Train Loss: 0.195995 | Val Loss: 0.161549 | Wait: 3/8\n",
      "Epoch 008 | Train Loss: 0.195029 | Val Loss: 0.182629 | Wait: 4/8\n",
      "Epoch 008 | Train Loss: 0.195029 | Val Loss: 0.182629 | Wait: 4/8\n",
      "Epoch 009 | Train Loss: 0.195565 | Val Loss: 0.154170 | Wait: 0/8\n",
      "Epoch 009 | Train Loss: 0.195565 | Val Loss: 0.154170 | Wait: 0/8\n",
      "Epoch 010 | Train Loss: 0.191815 | Val Loss: 0.157204 | Wait: 1/8\n",
      "Epoch 010 | Train Loss: 0.191815 | Val Loss: 0.157204 | Wait: 1/8\n",
      "Epoch 011 | Train Loss: 0.187682 | Val Loss: 0.181665 | Wait: 2/8\n",
      "Epoch 011 | Train Loss: 0.187682 | Val Loss: 0.181665 | Wait: 2/8\n",
      "Epoch 012 | Train Loss: 0.187381 | Val Loss: 0.214428 | Wait: 3/8\n",
      "Epoch 012 | Train Loss: 0.187381 | Val Loss: 0.214428 | Wait: 3/8\n",
      "Epoch 013 | Train Loss: 0.188423 | Val Loss: 0.145286 | Wait: 0/8\n",
      "Epoch 013 | Train Loss: 0.188423 | Val Loss: 0.145286 | Wait: 0/8\n",
      "Epoch 014 | Train Loss: 0.187545 | Val Loss: 0.216686 | Wait: 1/8\n",
      "Epoch 014 | Train Loss: 0.187545 | Val Loss: 0.216686 | Wait: 1/8\n",
      "Epoch 015 | Train Loss: 0.179768 | Val Loss: 0.168579 | Wait: 2/8\n",
      "Transformer Test MSE: 0.16772279143333435\n",
      "Transformer Test R²: 0.9052162766456604\n",
      "Epoch 015 | Train Loss: 0.179768 | Val Loss: 0.168579 | Wait: 2/8\n",
      "Transformer Test MSE: 0.16772279143333435\n",
      "Transformer Test R²: 0.9052162766456604\n"
     ]
    }
   ],
   "source": [
    "# Transformer baseline using PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Train/test split without shuffling to respect temporal order\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Feature scaling (fit on train only)\n",
    "scaler_tf = StandardScaler()\n",
    "X_train_arr = scaler_tf.fit_transform(X_train_tf.values)\n",
    "X_test_arr = scaler_tf.transform(X_test_tf.values)\n",
    "y_train_arr = y_train_tf.values.astype(np.float32)\n",
    "y_test_arr = y_test_tf.values.astype(np.float32)\n",
    "\n",
    "# Torch tensors and data loaders\n",
    "X_train_tensor = torch.tensor(X_train_arr, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_arr, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_arr, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test_arr, dtype=torch.float32).unsqueeze(1)\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=False)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, n_features, d_model=64, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.feature_proj = nn.Linear(1, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, n_features)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = self.feature_proj(x)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.head(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_tf = TransformerRegressor(n_features=X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_tf.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "best_val = float('inf')\n",
    "patience = 8\n",
    "wait = 0\n",
    "n_epochs = 15\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model_tf.train()\n",
    "    train_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model_tf(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    avg_train = float(np.mean(train_losses))\n",
    "\n",
    "    model_tf.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            preds = model_tf(xb)\n",
    "            val_losses.append(criterion(preds, yb).item())\n",
    "    avg_val = float(np.mean(val_losses)) if val_losses else float('nan')\n",
    "\n",
    "    if avg_val < best_val - 1e-6:\n",
    "        best_val = avg_val\n",
    "        wait = 0\n",
    "        os.makedirs(\"models/model5\", exist_ok=True)\n",
    "        torch.save({'model_state_dict': model_tf.state_dict(), 'scaler': scaler_tf}, 'models/model5/transformer_model.pt')\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {avg_train:.6f} | Val Loss: {avg_val:.6f} | Wait: {wait}/{patience}')\n",
    "    if wait >= patience:\n",
    "        print('Early stopping triggered.')\n",
    "        break\n",
    "\n",
    "# Final evaluation\n",
    "model_tf.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_tf(X_test_tensor.to(device)).cpu().numpy().squeeze()\n",
    "\n",
    "mse_tf = mean_squared_error(y_test_arr, preds)\n",
    "r2_tf = r2_score(y_test_arr, preds)\n",
    "print('Transformer Test MSE:', mse_tf)\n",
    "print('Transformer Test R²:', r2_tf)\n",
    "\n",
    "# Reload example:\n",
    "# checkpoint = torch.load('models/model5/transformer_model.pt')\n",
    "# model_tf.load_state_dict(checkpoint['model_state_dict'])\n",
    "# scaler_loaded = checkpoint['scaler']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cis5200)",
   "language": "python",
   "name": "cis5200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
